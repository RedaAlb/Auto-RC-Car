{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Look into using the `Dataset` object for the datasets [helpful link](https://www.tensorflow.org/guide/data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import shuffle\n",
    "import random\n",
    "import shutil\n",
    "\n",
    "from data_sequence import DataSequence\n",
    "\n",
    "\n",
    "# Some parameters\n",
    "MODELS = [\"forward\", \"left\", \"right\"]  # Also represents the class names.\n",
    "MODEL_I = 0  # Model index, determines which module to train, hence which data to use, (chosen from MODELS).\n",
    "\n",
    "# The folder where the data is stored. This is here to easily switch between local and Google Colab env.\n",
    "PATH_TO_DATA_DIR = \"data\"\n",
    "# PATH_TO_DATA_DIR = \"drive/My Drive/Auto_RC_Car/data\"  # For when using Google Colab.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "VALIDATION_SPLIT = 0.1\n",
    "TEST_SPLIT = 0  # Zero for no test set.\n",
    "\n",
    "USE_DATA_AUG = True\n",
    "\n",
    "HEIGHT_CROP = 95  # How many pixels to crop from the top.\n",
    "USE_SQUARE_IMG = True  # Whether to re-size the image to a square image.\n",
    "IMGS_SHAPE = (240-HEIGHT_CROP, 320, 3)  # Image dims to use for training.\n",
    "\n",
    "if USE_SQUARE_IMG:\n",
    "    IMGS_SHAPE = (IMGS_SHAPE[0], IMGS_SHAPE[0], 3)\n",
    "\n",
    "BATCH_SIZE = 256  # Needs to be even, because half will be original data, half augmented data.\n",
    "\n",
    "NUM_CLASSES = 3\n",
    "\n",
    "# Ratios of classes in each batch. I do this because there are significantly more forward samples (stayin in lane).\n",
    "FORWARD_RATIO = 0.5\n",
    "LEFT_RATIO    = 0.25\n",
    "RIGHT_RATIO   = 0.25\n",
    "\n",
    "# Data augmentation parameters\n",
    "ROT_RANGE = 2\n",
    "BRIGHT_MIN = 0.2\n",
    "BRIGHT_MAX = 1.5\n",
    "HORI_FLIP = True\n",
    "\n",
    "SEED_NUM = 2\n",
    "\n",
    "# General setup\n",
    "tf.random.set_seed(SEED_NUM)\n",
    "np.random.seed(SEED_NUM)\n",
    "random.seed(SEED_NUM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_seq = DataSequence(IMGS_SHAPE, BATCH_SIZE, NUM_CLASSES, USE_DATA_AUG, SEED_NUM)\n",
    "\n",
    "data_seq.load_data(path_to_data_dir=PATH_TO_DATA_DIR, model_to_load=MODELS[MODEL_I])\n",
    "data_seq.pre_process_data(HEIGHT_CROP, USE_SQUARE_IMG)\n",
    "data_seq.split_into_classes()\n",
    "data_seq.split_val_test(VALIDATION_SPLIT, TEST_SPLIT, FORWARD_RATIO, LEFT_RATIO, RIGHT_RATIO)\n",
    "data_seq.create_aug_gen(ROT_RANGE, BRIGHT_MIN, BRIGHT_MAX, HORI_FLIP)\n",
    "\n",
    "\n",
    "# Just getting a small sample of the training data to visualise and test the data augmentation with.\n",
    "x_sample_batch, y_sample_batch = data_seq.get_batch(32)\n",
    "print(\"\\nTemp samples:\", x_sample_batch.shape, y_sample_batch.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualising the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To plot images in a grid\n",
    "def plot_imgs(images, labels, rows=3, cols=3, fig_w=15, fig_h=10):\n",
    "    fig, axis = plt.subplots(rows, cols, figsize=(fig_w, fig_h))\n",
    "    fig.tight_layout()\n",
    "\n",
    "    sample_index = 0\n",
    "    for row in range(rows):\n",
    "        for col in range(cols):\n",
    "            if sample_index >= images.shape[0]:\n",
    "                break \n",
    "            img = images[sample_index]\n",
    "            img = img * 255\n",
    "            img = img.astype(int)\n",
    "            \n",
    "            label = labels[sample_index]\n",
    "            \n",
    "            sample_index += 1\n",
    "\n",
    "            ax = axis[row, col]\n",
    "            ax.set_title(str(label))\n",
    "            ax.imshow(img)\n",
    "            ax.axis(\"off\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_imgs(x_sample_batch, y_sample_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualising batch samples.\n",
    "data_batch = data_seq.__getitem__(0)\n",
    "print(data_batch[0].shape, data_batch[1].shape)\n",
    "plot_imgs(data_batch[0], data_batch[1], rows=4, cols=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tf.keras.Input(shape=IMGS_SHAPE)\n",
    "\n",
    "x = layers.Conv2D(24, 5, strides=2, activation=\"elu\")(inputs)\n",
    "x = layers.MaxPooling2D(2)(x)\n",
    "\n",
    "x = layers.Conv2D(36, 5, activation=\"elu\")(x)\n",
    "x = layers.MaxPooling2D(2, padding=\"same\")(x)\n",
    "\n",
    "x = layers.Conv2D(48, 5, padding=\"same\", activation=\"elu\")(x)\n",
    "x = layers.MaxPooling2D(2)(x)\n",
    "\n",
    "x = layers.Conv2D(64, 3, padding=\"same\", activation=\"elu\")(x)\n",
    "# x = layers.Conv2D(64, 3, activation=\"elu\")(x)\n",
    "\n",
    "x = layers.Flatten()(x)\n",
    "\n",
    "x = layers.Dense(1024, activation=\"elu\")(x)\n",
    "# x = layers.Dense(1024, activation=\"elu\")(x)\n",
    "\n",
    "outputs = layers.Dense(3, activation=\"softmax\")(x)\n",
    "\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(lr=1e-3)\n",
    "\n",
    "model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=[\"accuracy\"])\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 30\n",
    "MODEL_NAME = \"br_org_paddingSame_resized_cropped_largeFNN\"\n",
    "SAVE_MODEL = True\n",
    "\n",
    "try:\n",
    "    shutil.rmtree(\"logs\")\n",
    "except FileNotFoundError as err:\n",
    "    pass\n",
    "\n",
    "callbacks = [\n",
    "    tf.keras.callbacks.TensorBoard(log_dir='./logs')\n",
    "]\n",
    "# command to view -> tensorboard --logdir=./logs  \n",
    "\n",
    "\n",
    "\n",
    "history = model.fit(data_seq,\n",
    "                    steps_per_epoch = data_seq.train_n_samples // BATCH_SIZE,\n",
    "                    validation_data = (data_seq.x_val, data_seq.y_val),\n",
    "                    validation_steps = data_seq.x_val.shape[0] // BATCH_SIZE,\n",
    "                    epochs = EPOCHS,\n",
    "                    callbacks=callbacks,\n",
    "                    shuffle=False)\n",
    "\n",
    "\n",
    "\n",
    "# Saving the trained model and its history.\n",
    "if SAVE_MODEL:\n",
    "    model.save(f\"saved_models/model_{MODELS[MODEL_I]}_{MODEL_NAME}.h5\")\n",
    "    \n",
    "    history_array = np.array([history.history[\"loss\"],\n",
    "                              history.history[\"accuracy\"],\n",
    "                              history.history[\"val_loss\"],\n",
    "                              history.history[\"val_accuracy\"]])\n",
    "    with open(f\"saved_models/history_{MODELS[MODEL_I]}_{MODEL_NAME}.npy\", \"wb\") as file:\n",
    "        np.save(file, history_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history[\"loss\"])\n",
    "plt.plot(history.history[\"val_loss\"])\n",
    "plt.legend([\"training\", \"validation\"])\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Loss plot\")\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history[\"accuracy\"])\n",
    "plt.plot(history.history[\"val_accuracy\"])\n",
    "plt.legend([\"training\", \"validation\"])\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"Accuracy plot\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing data augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rotation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen_rot = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    rotation_range=ROT_RANGE,\n",
    ")\n",
    "\n",
    "data_flow = datagen_rot.flow(x_sample_batch, y_sample_batch, batch_size=32)\n",
    "plot_imgs(data_flow.next()[0], data_flow.next()[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Brightness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen_bright = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    brightness_range=(BRIGHT_MIN, BRIGHT_MAX),\n",
    "    rescale=1./255\n",
    ")\n",
    "\n",
    "data_flow = datagen_bright.flow(x_sample_batch, y_sample_batch, batch_size=32)\n",
    "plot_imgs(data_flow.next()[0], data_flow.next()[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Horizontal Flipping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen_flip = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    horizontal_flip=HORI_FLIP,\n",
    ")\n",
    "\n",
    "data_flow = datagen_flip.flow(x_sample_batch, y_sample_batch, batch_size=32)\n",
    "plot_imgs(data_flow.next()[0], data_flow.next()[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing/visualising all data augmentations together "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_aug_data = data_seq.datagen.flow(x_sample_batch, y_sample_batch, batch_size=32).next()\n",
    "\n",
    "aug_batch_imgs = data_aug_data[0]\n",
    "aug_batch_labels = data_aug_data[1]\n",
    "\n",
    "print(\"Augmented batch:\", aug_batch_imgs.shape, aug_batch_labels.shape)\n",
    "\n",
    "plot_imgs(aug_batch_imgs, aug_batch_labels, rows=5, fig_h=20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tf_gpu] *",
   "language": "python",
   "name": "conda-env-tf_gpu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 353,
   "position": {
    "height": "695px",
    "left": "227.948px",
    "right": "20px",
    "top": "304.91px",
    "width": "800px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "block",
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
